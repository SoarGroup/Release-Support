% ----------------------------------------------------------------------------
\typeout{-------------------------------- CHUNKING ----------------------------------}
\chapter{Procedural Knowledge Learning}
\label{CHUNKING}
\index{chunking}
\index{chunk}
\index{result}
\index{subgoal}

% ----------------------------------------------------------------------------
% ----------------------------------------------------------------------------
\section{Chunking}

\textbf{Chunking} is Soar's experience-based mechanism to learn new procedural knowledge.  Chunking utilizes Soar's impasse-driven model of problem decomposition into subgoals to create new productions dynamically during task execution.  These new productions, called \textbf{chunks}, summarize the problem-solving that was required to produce the results of each subgoal. When a chunk is built, it is added to production memory.  In future similar situations, the agent will not create a similar subgoal, thus avoiding the potentially expensive problem-solving that would have occurred.  Instead, the chunk will fire and create the same result in a single step.  

Chunking can effect both speed-up and transfer learning.  Chunks can effect speed-up learning because they compress all of the problem-solving needed to produce a result into a single step.  For some real-world agents, hundreds of rule firings are compressed into a single rule firing.  Chunks can effect transfer learning because they generalize the problem-solving in such a way that they can apply to other situations that are similar but have not yet been experienced.

Chunks are created whenever one subgoal creates a result; since most Soar programs are continuously subgoaling and returning results to higher-level states, chunks are typically created continuously as Soar runs.  Note that Soar builds the chunk as soon as the result is created, rather than waiting until the impasse is resolved.


% ----------------------------------------------------------------------------
% ----------------------------------------------------------------------------
\section{Explanation-based Chunking}

Explanation-based chunking improves on previous versions of chunking by learning rules that are qualitatively more general and more expressive.  In fact, they now can generalize any element of the rule and have the full expressive power of hand-written rules. Here is an example of a chunk EBC learned from the arithmetic demo agent and how it differs from chunks learned in previous versions of Soar.

\begin{figure}
	\centering
	{\small
	\subfigure{
	\begin{verbatim}
		sp {chunk-94*process-column*apply*write-result
		    (state <s1> ^operator <o1>
		                ^arithmetic-problem <a1>
		                ^one-fact 1
		
		                ^top-state <s1>
		                ^arithmetic <a2>
		                ^arithmetic <a3>)
		    (<o1> ^name process-column)
		    (<a1> ^operation subtraction
		          ^current-column <c1>)
		    (<c1> -^new-digit1 <n1>
		          ^digit1 0
		          ^digit2 7
		          ^next-column <n2>)
		    (<n2> ^digit1 0
		          ^new-digit1 9
		          ^next-column <n3>)
		    (<n3> ^digit1 5
		          ^new-digit1 4)
		    (<a3> ^add10-facts <a4>)
			
		    (<a4> ^digit1 0
		          ^digit-10 10)
		    
		    
		    (<a2> ^subtraction-facts <s2>
		          ^subtractions-facts <s3>
		          ^subtraction-facts <s4>)
		    (<s2> ^digit1 10  ^digit2 1
		          ^result 9)
		    (<s3> ^digit1 5   ^digit2 1
		          ^result 4)
		    (<s4> ^digit1 10  ^digit2 7
		          ^result 3)
		    -->
		    (<c1> ^result 3)
		}
	\end{verbatim}
	}
	\subfigure{
	\begin{verbatim}
		sp {chunk-94*process-column*apply*write-result
		    (state <s1> ^operator <o1>
		                ^arithmetic-problem <a1>
		                ^one-fact <o2>
		                ^one-fact <o3>
		                ^top-state <t1>
		                ^arithmetic <a2>
		                ^arithmetic <a3>)
		    (<o1> ^name process-column)
		    (<a1> ^operation subtraction
		          ^current-column <c1>)
		    (<c1> -^new-digit1 <n1>
		          ^digit1 { <d2> < <d1> }
		          ^digit2 <d1>
		          ^next-column <n2>)
		    (<n2> ^digit1 { <d3> < <o3> }
		          ^new-digit1 <n3>
		          ^next-column <n4>)
		    (<n4> ^digit1 { <d4> >= <o2> }
		          ^new-digit1 <n5>)
		    (<a3> ^add10-facts <a4>
			      ^add10-facts <a5>)
		    (<a4> ^digit1 <d2>
		          ^digit-10 { <d5> >= <d1> })
		    (<a5> ^digit1 <d3>
		          ^digit-10 { <d6> >= <o3> })
		    (<a2> ^subtraction-facts <s2>
		          ^subtractions-facts <s3>
		          ^subtraction-facts <s4>)
		    (<s2> ^digit1 <d6>  ^digit2 <o3>
		          ^result <n3>)
		    (<s3> ^digit1 <d4>  ^digit2 <o2>
		          ^result <n5>)
		    (<s4> ^digit1 <d5>  ^digit2 <d1>
		          ^result <r1>)
		    -->
		    (<c1> ^result <r1>)
		}
	\end{verbatim}
	}
	}
	\caption{Comparing a traditional chunk (left) with an explanation-based chunk (right) in the arithmetic demo agent.  In Soar 9.4, the arithmetic agent would learn 1263 rules like the one on the left.  In Soar 9.6, the same agent learns under 10 rules like the one on the right.}
\end{figure}

To achieve this, chunking needs information about why rules matched and what the relationships are between those rules.  It needs to know what is generalizable and what limits are there on those generalizations. Prior versions of chunking analyzed a literal history of the rule instances that matched in the substate, which we call a working memory trace, so most of that information was not readily available.

Since this working memory trace provides limited information, chunking produced very specific rules in which only Soar identifiers were variablized and all other elements tested the exact values that matched.  To improve on this and produce more general chunks, EBC instead does an analysis of the underlying network of hand-written rules that matched in the substate and led to the results.  We call this network the explanation trace:

\index{chunking!instantiation}
Note that this trace is generated dynamically as rules match.  Whenever a rule matches during agent execution, Soar creates an internal record of the rule that fired, called an \textbf{instantiation}.  (Each box in the explanation traces below represents an instantiation that was created during task execution within a particular substate.) The instantiation contains both instance information about what matched (the working memory elements) and explanatory information about why they matched (the rules and actions in the original rules that contains variables, constraint tests, RHS actions, etc.).  

Even architectural WMEs have special instantiations that explain why they were created.  For example, an architectural instantiation is created for each \soar{\carat item} attribute automatically made for operator tie impasse substates; the explanation causes the \soar{\carat item} augmentation to be dependent on the operator in the superstate that led to it.  Similarly, structures created by semantic and episodic memory in the substate have architectural instantiations that explain their genesis.

\index{chunking!backtracing}
All of the instantiations that were created in a substate form the instantiation graph of that substate.  As chunking \textbf{backtraces} through the instantiation graph, it determines the subset of instantiations that contributed to a result, which constitutes the explanation trace for a learning episode.  (So, the explanation trace is a subgraph of the instantiation graph.)

\begin{figure}
	\insertfigure{chunking-wm-vs-exp-trace.png}{\textwidth}
	\insertcaption{A close-up of a trace showing differences between a working memory trace (left) vs an explanation trace (right).  The working memory trace only contains the literal values of the WMEs that matched.  The explanation trace, on the other hand, contains variables and various constraints on the values those variables can hold.}
	\label{fig:chunking-wm-vs-exp}
\end{figure}

\begin{figure}
	\insertfigure{chunking-trace.png}{\textwidth}
	\caption{A visualization of the explanation trace of a chunk learned by the arithmetic agent.  Each box represents a rule that fired in the substate.  Arrows show dependencies between rules that create working memory elements and conditions that test those working memory elements.}
	\label{fig:chunking-trace}
\end{figure}

EBC uses the explanation trace to determine (1) how variables were used during a problem-solving episode and (2) what constraints on those variables had to be met in order for the substate rules to match.  EBC then uses the results of this analysis to create more expressive and general rules, which can contain the full gamut of tests that hand-written rules can and can have any element variablized.


% ----------------------------------------------------------------------------
% ----------------------------------------------------------------------------
\section{Overview of the EBC Algorithm}
\label{CHUNKING-ebc}

% ----------------------------------------------------------------------------
\subsection{Identity}
\index{chunking!identity}

Before we can discuss the algorithm, we must first define one of its central concepts: \soarb{identity}.  As previously mentioned, EBC traverses an explanation trace of the problem-solving that occurred in the substate to determine which variables in different rule instances refer to the same underlying object.  

Basic concepts:

\begin{itemize}
	\item Rule actions and rule conditions each have three \textit{elements}:
	\vspace{-6pt}
	\begin{itemize}
		\item For actions, the three elements refer to the identifier, attribute and value of the WME being created.
		\vspace{-6pt}
		\item For conditions, the three elements refer to the symbol in the positive equality test for the identifier, attribute and value of the condition.  For example, the last condition of rule 2 in Figure \ref{fig:chunking-trace2} has \soar{<s>} as the identifier element, number as the attribute element, and \soar{<y>} as the value element.
	\end{itemize}
	\vspace{-6pt}
	\item An element is either a variable or a literal constant.
	\vspace{-6pt}
	\item Two \textit{variables} are said to \textit{share an identity} if they both refer to the same underlying object.
	\vspace{-6pt}
	\begin{itemize}
		\item Another way to say this is that an identity is the set of all variables in a trace that refer to the same underlying object.
	\end{itemize}
	\vspace{-6pt}
	\item The NULL identity is a special identity that indicates an element which must contain a specific value cannot be generalized.
	\vspace{-6pt}
	\index{chunking!literalization}
	\begin{itemize}
		\item All literal constants in rules are automatically assigned the NULL identity.
		\vspace{-6pt}
		\item A variable's identity can also be mapped to the NULL identity.  When this happens, we say the identity has been literalizated.
	\end{itemize}
	\vspace{-6pt}
\end{itemize}

There are two ways that an explanation trace can show a shared identity:

\begin{enumerate}
	\item Variables that have the same name and are in the same rule firing will share an identity

	This is the trivial case.  The basic semantics of rules implies that the same variable in a rule references the same underlying object.

	\vspace{-6pt}
	\item If a RHS action of one rule creates a WME and a LHS condition of another rules tests that same WME, then all variables in the condition and actions will possess the same identity as their counterpart's corresponding element. 

	The interaction between the two rules indicates a shared identity between their corresponding variables.
	\vspace{-6pt}
\end{enumerate}

To get a better picture of what a shared identity is, consider the following two simple rules and an explanation trace of how they matched in a substate:

\begin{figure}
	\insertfigure{chunking-trace2.png}{\textwidth}
	\caption{Explanation trace of two simple rules that match in a substate}
	\label{fig:chunking-trace2}
\end{figure}

In Figure \ref{fig:chunking-trace2}, the connection between rule 2 and rule 1 will \textit{unify} the identities of \soar{<s>}, \soar{<x>} and \soar{<y>} in rule 1 with the identities of \soar{<s>}, \soar{<x>} and \soar{<y2>} in rule 2.  So, the \soar{<x>} in rule 2 shares the same identity as the \soar{<x>} in rule 1.  Similarly, the \soar{<y2>} in rule 2 shares the same identity as \soar{<y>} in rule 1.  In contrast, the \soar{<y>} in rule 2 does NOT share the same identity as the \soar{<y>} in rule 1. 

It doesn't matter that the \soar{<y>} in rule 1 uses the same variable name as the \soar{<y>} in rule 2.  It also doesn't matter that both conditions with \soar{<y>} happen to match the same working memory element, \soar{(S1 \carat number 3)}.  In terms of sharing an identity, the only thing that matters is how the rules interact, namely whether there's a connection between elements in the condition of one rule and elements in the actions of another rule.

All literal values, for example all of the attribute in Figure \ref{fig-chunking-trace} (\soar{superstate}, \soar{number}, \soar{intermediate1}, etc.) are considered members of the \textit{NULL identity}.

\index{chunking!literalization}
Variable identities can also be mapped to the NULL identity, which we call \textbf{literalization}.  There are two ways that an explanation trace can show an identity literalization:

\begin{enumerate}
	\item If a RHS action of one rule creates a WME element using a constant, literal value in an element and a LHS condition tests that element, then the identity of the condition's variables is literalized and mapped to the NULL identity. 

	Because the variable in the condition matched a rule that will always create the same constant, literal value, the condition's variable must have that same value.  Otherwise, it would not have matched.
	\vspace{-6pt}
	
	\item If a RHS action of one rule creates a WME element using a variable and a LHS condition tests that that element is a specific value, then the identity of the action's variables is literalized and mapped to the NULL identity. 

	Because the condition requires that the rule that created the matched WME to have a specific constant, literal value, the action's variable must have that same value.  Otherwise, it would not have created something that matched the condition. 
\end{enumerate}

Identities are the basis of nearly every mechanism in explanation-based chunking.  EBC's identity analysis algorithm, which is a fairly complicated process, determines all shared identities in an explanation trace.  Figure \ref{fig:chunking-trace-identity} shows an explanation trace after identity analysis has been performed.  Elements that share an identity in the figure are colored the same.

\begin{figure}
	\insertfigure{chunking-trace-identity.png}{\textwidth}
	\caption{}
	\label{fig:chunking-trace-identity}
\end{figure}

While it's not readable in this figure, note that each identity is assigned a numeric ID.  Both the explainer and the visualizer annotate elements of an explanation with the identity ID in square brackets.  These numbers are simply syntactic sugar to ease debugging and make traces easier to understand.  Underneath the hood, every test in a condition has a pointer to more complicated identity data structure that will be discussed in more detail in Section \ref{CHUNKING-prior-identities} on the identity graph. 

\begin{figure}
	\insertfigure{chunking-ebc-components.png}{\textwidth}
	\caption{Five components of EBC and when they occur}
	\label{fig:chunking-ebc-components}
\end{figure}

\begin{enumerate}
	\item \textbf{Operationality analysis} \hfill
	This component determines which conditions in an explanation trace tested working memory elements in a superstate.  The rule formation component will use these conditions as a basis for the left-hand side of the chunk.  While it does have a few key new differences, this is the one step that is similar to previous versions of chunking.

	\item \textbf{Identity analysis} \hfill
	This component determines which variables in an explanation trace share the same identity.  It also determines which identities are ineligible for variablization because they were tested against literal values in some rules.  

	Note that this component has two distinct mechanisms that occur at very different times.  The first mechanism, identity propagation, occurs constantly while problem-solving in the substate.  The second mechanism, identity graph manipulation, occurs during the learning episode

	\item \textbf{Relevant operator selection knowledge tracking]} \hfill
	This component also does most of its work before the learning episode.  Whenever an operator is selected, it analyzes what operator selection knowledge was relevant and caches that relevant knowledge in all rule instances that tests that operator. 

	\item \textbf{Constraint tracking} \hfill
	This component keeps track of every value or relational constraint (e.g. \soar{<> <x>}, \soar{>= 3.14}, \soar{<< disjunction of constants >>}) placed on the various variables that share an identity.  It is used by the rule formation step to make sure all constraints required are enforced by the learned rule.

	\item \textbf{Rule Formation} \hfill
	The above four components performed the analysis that EBC needs to form a general but correct rule.  This final component uses the results of that analysis to actually build the new rule.  This is a complex component that has seven different stages.  If a valid rule is created, Soar immediately adds the rule to production memory.
\end{enumerate}

The following sections will describe each component in more detail. 


% ----------------------------------------------------------------------------
% ----------------------------------------------------------------------------
\section{What EBC Does Prior to the Learning Episode}
\label{CHUNKING-prior}
\index{result}
\index{subgoal}

While most of the work that explanation-based chunking performs occurs during the learning episode, i.e. after a rule in a substate fires and Soar detects that a result will be created, some critical aspects of the analysis it performs also occur prior to the learning episode, during problem-solving in the substate.  The two points when that happens is when a rule fires in a substate and when an operator is selected in a substate.

% ----------------------------------------------------------------------------
\subsection{Identity Assignment and Propagation}
\label{CHUNKING-prior-identities}

Each instantiation describes the working memory elements that matched each condition and the working memory elements and preferences that are created by each action.  With the introduction of EBC, all instantiations now also store the underlying explanation behind each condition and action as defined by the original rule: which elements in conditions are variables and which ones are literal constants, which variables are the same variables, what constraints must be met on the values of each variable and any relationships between variables.

\index{chunking!identity}
EBC uses this underlying logic to determine the identities of objects used during the problem-solving.  Identities are not simply IDs.  Each identity is a declarative object that describes a set of variables across multiple rule firings and the various properties they hold. 

\emph{When an instantiation is created, EBC assigns all elements of every condition and action to an identity, creating new identities as necessary.} Identities are created and propagated using the following rules:

\begin{enumerate}
	\item If the same variable appears in multiple places in the same rule, it must be assigned the same identity.

	\item The NULL Identity is assigned to any element with a literal value in the original rule.

	\item A new identity is created and assigned for:
	\begin{enumerate}
		\item All right-hand side action elements that produce a new Soar identifier in the substate
	
		These are also known as unbound RHS variables.

		\item All elements of conditions that matched superstate WMEs

		It is important to note that each condition that matches to a superstate WME is considered independent and are given new identities, even if they match the same superstate WME.
	\end{enumerate}
	\item An existing identity is propagated for:

	\begin{enumerate}
		\item Any condition element that matched a substate WME with existing identities

		Each element is assigned the identity found in the corresponding element of the action of the rule that created that WME.  This propagates identities forward through the explanation trace, which allows us to represent that the variable in the condition refers to the same object as the variable in the action of the other rule.

		\item Any element that matches special working memory elements labeled as singletons are assigned the same identity.

		\index{singleton}
		\soarb{Singletons} are working memory elements that are guaranteed to only have a single possible value in a state.  The most important singleton is the local \soar{\carat superstate} singleton, which is an architecturally created WME that links the substate to the superstate, for example \soar{(S2 \carat superstate S1)}.  Since we know that it's impossible for there to be two superstate features in a state, all conditions that test that singleton WME will be assigned the same identities.

		While there are a variety of built-in singletons for architecturally-created WMEs, users can also specify their own domain-specific singletons.  See Section \ref{CHUNKING-usage-tuning-conditions} for more information about user singletons.  The full list of architecturally-created singletons can be found in the chunk command's help entry in Section \ref{chunk}.
	\end{enumerate}
\end{enumerate}

Note that rule 1 may conflict with other rules.  For example, if a variable appears in two different conditions, then two different identities may propagate into each one of them.  In such cases, rule 1 is always enforced and propagation is ignored. During the second phase of identity analysis, which occurs during the actual learning episode, EBC will re-examine all of the condition-action pairs as it performs a backward traversal of the explanation trace and fix the missing propagations.  It does this by creating and manipulating an identity graph that can correctly incorporate all identity relationships.

% ----------------------------------------------------------------------------
\subsection{Relevant Operator Selection Knowledge Tracking}
\label{CHUNKING-prior-osk}
\index{Operator Selection Knowledge (OSK)|see{Context-Dependent Preference Set}}

As described in the beginning of this chapter, chunking summarizes the processing required to produce the results of subgoals. Traditionally, the philosophy behind how an agent should be designed was that the path of operator selections and applications from an initial state in a substate to a result would always have all necessary tests in the operator proposal conditions and any goal test, so only those items would need to be summarized. The idea was that in a properly designed agent, a substate's operator evaluation preferences lead to a more efficient search of the space but do not influence the correctness of the result. As a result, the knowledge used by rules that produce such evaluation preferences should not be included in any chunks produced from that substate.

In practice, however, it may make sense to design an agent so that search control does affect the correctness of search. Here are just two examples:

\begin{enumerate}
	\item Some of the tests for correctness of a result are included in productions that prefer operators that will produce correct results. The system will work correctly only when those productions are loaded.

	\item An operator is given a worst preference, indicating that it should be used only when all other options have been exhausted. Because of the semantics of worst, this operator will be selected after all other operators; however, if this operator then produces a result that is dependent on the operator occurring after all others, this fact will not be captured in the conditions of the chunk.
\end{enumerate}

\index{chunking!correctness}
\index{chunking!relevant operator selection knowledge}
In both of these cases, part of the test for producing a result is \emph{implicit} in search control productions. This move allows the explicit state test to be simpler because any state to which the test is applied is guaranteed to satisfy some of the requirements for success. However, chunks created in such a problem space will not be correct because important parts of the superstate that were tested by operator evaluation rules do not appear as conditions. The chunks would not accurately summarize the processing in that problem state.  The tracking of \textbf{Relevant Operator Selection Knowledge} (ROSK) is a way to address this issue.

\index{chunking!backtracing}
Relevant operator selection knowledge is the set of necessary operator evaluation preferences that led to the selection of an operator in a subgoal.  As previously described, whenever Soar learns a rule, it recursively backtraces through rule instances to determine which conditions to include in the final chunk or justification. With the ROSK, not only does Soar backtrace through each rule instance that created a matched working memory element, but it also backtraces through every rule instance that created preferences in the ROSK for any operator that gave those matched WMEs o-support. By backtracing through that additional set of preferences at each step of the backtrace, an agent will create more specific chunks that incorporate the goal-attainment knowledge encoded in the operator evaluation rules.

Specifically, this component does two things:

\begin{enumerate}
	\item When an operator is selected, it analyzes the operator preferences that led to the decision, and caches any operator selection knowledge that played a necessary role in the selection. 

	All necessity preferences, i.e. prohibit and require preferences, are always included in the ROSK since they inherently encode the correctness of whether an operator is applicable in a problem space. In contrast, some desirability preferences (rejects, betters, worses, bests, worsts and indifferents) are included in the ROSK depending on the role they play in the selection of the operator. 

	How Soar determines which of those preferences to include in the ROSK is determined by the preference semantics it uses to choose an operator. During the decision phase, operator preferences are evaluated in a sequence of seven steps or filters, in an effort to select a single operator, as described in Section \ref{PREFERENCES}.  Each step, or filter, handles a specific type of preference.  As the preference semantics are applied at each step to incrementally filter the candidate operators to a potential selected operator, EBC incrementally adds operator preferences to the ROSK based on the preferences that were instrumental in applying each filter.  A more detailed explanation of the logic used at each step can be found in Section \ref{CHUNKING-subtleties-osk}.

	\item When a rule matches which tests the currently selected operator, EBC caches the operator's ROSK in the instantiation of that rule.  

	Since that selection knowledge was necessary to select the operator needed for the rule to match, chunking must backtrace through that knowledge.  The operationality analysis component uses the cached ROSK to do this and incorporate the necessary operator selection reasoning knowledge into the learned rule.  For some types of agent designs, including operator selection knowledge is needed to ensure correctness.
\end{enumerate}


% ----------------------------------------------------------------------------
% ----------------------------------------------------------------------------
\section{What EBC Does During the Learning Episode}
\label{CHUNKING-during}

All of the previously discussed steps occurred during problem-solving in the substate as rules matched and operators were selected.  It is worth noting that the analysis performed prior to the learning episode is persistent and can be shared across learning episodes.  In other words, EBC can repeatedly re-use that analysis if it learns multiple chunks in the same substate.  

Every time a rule fires in a substate, Soar checks to see if any of the working memory elements created by the rule qualify as results.  This is when the actual learning episode begins.

% ----------------------------------------------------------------------------
\subsection{Calculating the Complete Set of Results}
\label{CHUNKING-during-results}
\index{result}

A chunk's actions are built from the results of a subgoal. A \textbf{result} is any working memory element created in the substate that is linked to a superstate. A working memory element is linked if its identifier is either the value of a superstate WME, or the value of an augmentation for an object that is linked to a superstate.

The results produced by a single production firing are the basis for creating the actions of a chunk. A new result can lead to other results by linking a superstate to a WME in the substate. This WME may in turn link other WMEs in the substate to the superstate, making them results. Therefore, the creation of a single WME that is linked to a superstate can lead to the creation of a large number of results. All of the newly created results become the basis of the chunk's actions.

\subsection{Backtracing: Operationality, Identity, and Constraint Analysis}
\label{CHUNKING-during-backtracing}
\index{chunking!backtracing}

When learning a new rule, EBC performs a dependency analysis of the productions that fired in a substate -- a process called backtracing. Backtracing works as follows.  For each instantiated production that creates a subgoal result, backtracing examines the explanation trace to determine which working memory elements matched each condition. If the working memory element is local to the substate, then backtracing recursively examines the instantiation that created that condition's matched working memory element. Thus, backtracing traces backwards through all rules that fired and created working memory elements that were used to produce a result.

If an instantiation being backtraced through tested a selected operator, EBC will backtrace through each instantiation that created a preference in that operator's relevant operator selection knowledge set.  This behavior is off by default and can be enabled with \soar{chunk add-osk on} (See Section \ref{chunk-add-osk}.

Multiple components of EBC perform their work during backtracing:  operationality analysis, identity analysis and constraint tracking.  The following sections will discuss what aspects of the agent's problem-solving are analyzed during backtracing.

\subsubsection{Operationality Analysis}
\label{CHUNKING-during-backtracing-operationality}

The traditional core function of chunking's backtracing is to determine which conditions in the working memory trace tested working memory elements accessible to the superstate.  These conditions will form the left-hand side of the rule.

The determination of which conditions to include is analogous to the concept of \textit{operationality} in explanation-based techniques. In classic EBL literature, operationality is typically defined as nodes in the explanation trace that are ``efficiently calculatable''.  In terms of Soar's problem-state computational model, operationality can be defined as any condition that tests knowledge linked to a superstate.  

As EBC is backtracing through rules that fired in a substate, it collects all of these operational conditions.  In other words, if a condition's matched working memory element is linked to a superstate, that condition will be included in the chunk's conditions.  Once the entire explanation trace is traversed, the operationality analysis will have determined exactly what superstate knowledge was tested during the process of creating a result. It then uses the collected conditions as the basis for the left-hand side of the newly learned rule.  

\index{chunking!negated conditions}
Negated conditions are included in a trace in the following way: when a production fires, its negated conditions are fully instantiated with its variables' appropriate values. This instantiation is based on the working memory elements that matched the production's positive conditions. If the variable is not used in any positive conditions, such as in a conjunctive negation, a dummy variable is used that will later become a variable in a chunk.  If the identifier used to instantiate a negated condition's identifier field is linked to the super- state, then the instantiated negated condition is added to the trace as a negated condition. In all other cases, the negated condition is ignored because the system cannot determine why a working memory element was not produced in the subgoal and thus allowed the production to fire. 

\textbf{Note:} Soar 9.6.0's explanation-based approach has led to one key change to Soar's operationality analysis.  In previous versions of chunking, chunking would never add two conditions to a chunk that matched the same superstate working memory element.  This made sense because chunking was based on a generalization of the working memory trace.  More than one condition that tested the same WME would be redundant.  Explanation-based chunking, though, learns based on the reasoning within the original hand-written rules.  Since the reasoning behind each of the two conditions may be different even if they matched the same WME, EBC must always add both conditions.  (Note that there are some exceptions. See Section \ref{CHUNKING-usage-tuning-conditions} on superstate singletons and user singletons.)

\subsubsection{Identity Analysis}
\index{chunking!identity}

The first phase of identity analysis, forward identity propagation, occurred as rules fired and instantiations were recorded.  Unfortunately, forward propagation alone will not produce correct identities.  We previously gave one reason why this is the case -- conditions may have conflicting identities propagated forward -- but there are other, more complicated reasons as well that are beyond the scope of this document. What is important to know is that a second phase of identity analysis will be performed during backtracing that will refine and correct the limitations of the initial forward propagation of identity. This second phase achieves these corrections by building an identity graph representing the identities involved during problem-solving and manipulating it as it backtraces through the rules that fired.

\subsubsection*{The Identity Graph}

The identity graph initially contains a node for each identity used in the explanation trace.  Each node can have multiple edges that point to children identities and a single directed \textit{join edge} that initially points back to itself.  As the agent backtraces through the explanation trace, EBC will manipulate the identity graph based on the condition-action pairs it encounters.

\begin{enumerate}
	\item \textbf{Joining identities} \hfill
	If a condition matches an action with a conflicting identity, EBC performs a join operation between the two identities. This chooses one identity as the \textit{joined identity} and points the join edges of the other identity and any previously joined identities to the new \textit{joined identity}.

	Note that any time EBC uses an element's identity, it is actually using the \textit{joined identity}.
	
	\item \textbf{Literalizing identities} \hfill
	If a condition/action with a variable element matches an action/condition with a literal element, EBC marks the variable's identity as literalized.  This means that any conditions in the final chunk that have elements with that identity will be considered to have the NULL identity, just like constants, and not be variablized.  Instead, the matched value will be used for that element.
	\index{chunking!NULL identity}
\end{enumerate}

	\nocomment{INSERT FIGURE OF IDENTITY GRAPH BEFORE AND AFTER BACKTRACING}

\subsubsection{Constraint Tracking}
\index{chunking!correctness}
\index{chunk!overgeneral}

Our definition of operationality is very clear and allows us to almost trivially determine operationality during task execution, but it does have one shortcoming: non-operational conditions, i.e. ones that don't test the superstate, can transitively place constraints on the values of variables in operational conditions that will appear in a chunk.  If our learning algorithm does not include these constraints, the learned rule will be missing knowledge and be over-general.

To handle this limitation, \textbf{\textit{EBC keeps track of all constraints found in non-operational conditions that it encounters while backtracing.}}

\begin{itemize}
	\item It stores constraints on the value a single identity, for example \soar{>= 0}, \soar{< 23}.
	\item It stores relational constraints between two identities, for example \soar{> <min>},  \soar{< <max>} or  \soar{<> <other>}.  
	\item EBC stores all of these constraints based on the underlying identities, not the variables used.  For example, if a variable \soar{<foo>} had the constraint \soar{<> <other>}, EBC would record that the variables that share the identity of \soar{<foo>} cannot have the same value as variables that share the identity of \soar{<other>}.
\end{itemize}

% ----------------------------------------------------------------------------
\subsection{Rule Formation}
\label{CHUNKING-during-formation}

This component of EBC has 7 distinct stages:

\begin{description}
	\item [Conditions and Action Creation]
	\vspace{-6pt}
	\item [Constraint Enforcement]
	\vspace{-6pt}
	\item [Identity-based Generalization]
	\vspace{-6pt}
	\item [Condition Merging]
	\vspace{-6pt}
	\item [Condition Polishing]
	\vspace{-6pt}
	\item [Rule Repair and Validation]
	\vspace{-6pt}
	\item [Condition Re-ordering]
	\vspace{-6pt}
\end{description}

\subsubsection{Condition and Action Creation}

This stage creates the basis for the left-hand and right-hand side of the rule.  To create the conditions of the chunk, it copies all conditions in the explanation trace that were flagged as operational during backtracing.  To form the actions of the chunk, it creates copies of the actions that produced all result WMEs and all children of those results that came along for the ride.

\subsubsection{Enforcement of Constraints}

This stage adds all constraints on non-operational conditions that were collected during backtracing.  As previously described, each constraint is indexed in terms of the identity it constrains.  So, \textit{if the identity being constrained exists in one of the conditions of the learned rule}, the constraint is added to that condition.

\subsubsection*{Inversion of Constraints}
\index{chunking!literalization}

There is one case where attaching a constraint can be tricky.  It happens when the constrained identity has been literalized but the constraint itself refers to an identity that has not been literalized, for example \soar{\{ > <x> 3 \}}.  While that constraint references a condition element that can only match a value of \soar{3}, the relationship between \soar{3} and the identity of \soar{<x>} must still hold (assuming \soar{<x>} appears in a different element somewhere else in the rule.)  Since these constraints still need to be enforced to ensure a correct rule, EBC will invert the constraint and attach it to a variable in another condition.  In this example, it would add a \soar{< 3} to some other condition with an element that had \soar{<x>}'s identity.

\subsubsection{Identity-Based Variablization}

To achieve any useful generality in chunks, identifiers of actual objects must be replaced by variables when the chunk is created; otherwise chunks will only ever fire when the exact same objects are matched.  At this point in the algorithm, all of the real work needed to determine the most general but correct variablization has already been performed by the identity analysis component.  So, this step simply needs to replace any element that has a non-NULL identity with a variable, making sure that elements with the same identity get the same variable.

Note that elements with identities that have been \textit{literalized} are considered members of the null identity and will not be variablized.

\subsubsection{Merge Redundant Conditions}

Any two conditions in the learned rule that share the same identities in all three elements can be combined.  In such cases, it is logically impossible for those two conditions to match two different WMEs and cause the same rules to match in the substate.  (If the two conditions were to match two different WMEs, at least one of the other rules in the explanation trace that had unified the two conditions would not have matched.)  As a result, EBC can safely merge those two conditions without losing generality.  

\subsubsection{Polish Conditions}

EBC polishes the conditions of the learned rule by pruning unnecessary constraints and combining disjunctions.

\begin{enumerate}
	\item \textbf{Merging conditions:}
	If two conditions contain the same identity in the equality tests of the identifier, attribute and value elements, then the two conditions will be merged.

	\item \textbf{Merging disjunctions:} 
	If an element in a condition has two disjunction tests, the constraints will be merged into a single disjunction that contains only the shared values. \soar{\{ << a b c >> << b c d >> <x>\}} becomes \soar{\{ <<b c >> <x> \}}, because it is impossible \soar{<x>} to be either \soar{a} or \soar{b}.  This will also eliminate any duplicate disjunctions.

	\item \textbf{Throwing out unnecessary constraints:} 
	If an element in a condition has been literalized but also has a literal constraint on its value, then the constraint is unnecessary and will be thrown out.  \soar{\{ >2 3\}} becomes \soar{3}.
\end{enumerate}

\subsubsection{Validate Rule and Repair Unconnected Conditions}

At this point, the rule is essentially formed.  Chunking must now make sure that the learned rule is fully operational and can be legally added to production memory.  A fully operational rule does not have any conditions or actions that are not linked to a goal state specified in the rule. 

If an unconnected action or condition is found, EBC will attempt to repair the rule by adding new conditions that provide a link from a state that is already tested somewhere else in the rule to the unconnected condition or action.

To repair the rule, EBC performs a search through working memory to find the shortest path of working memory elements that lead from a state identifier in the rule to a WME with the identifier in the unconnected condition or action.  A new condition is then added for every WME in that found path, which is then variablized.

Note that there may be multiple paths from a state to the unconnected identifier.  EBC does a breadth-first search, so it will find the shortest one.  

\subsubsection{Re-order Conditions}

Since the efficiency of the Rete matcher depends heavily upon the order of a production's conditions, the chunking mechanism attempts to write the chunk's conditions in the most favorable order. At each stage, the condition-ordering algorithm tries to determine which eligible condition, if placed next, will lead to the fewest number of partial instantiations when the chunk is matched. A condition that matches an object with a multi-valued attribute will lead to multiple partial instantiations, so it is generally more efficient to place these conditions later in the ordering.  This is the same process that internally reorders the conditions in user-defined productions, as mentioned briefly in Section \ref{ARCH-pm-structure}.


% ----------------------------------------------------------------------------
% ----------------------------------------------------------------------------
\section{Generality and Correctness of Learned Rules}
\label{CHUNKING-correctness}
\index{chunking!correctness}
\index{chunk!overgeneral}

Chunking is intended to produce the most general rule that is also correct. 

Generality is a measure of the space of similar situations that a rule can apply to.  A more general rule can be applied to a larger space of similar situations.  A rule is considered over-general if it can apply to situations in which the original problem-solving would have never occurred.  

Correctness is a requirement that the learned rule produces the exact same results that the original problem-solving would have produced.  In other words, if we inhibited a correct chunk so that it did not fire, the agent should subgoal, execute the same processing that it previously did in a similar subgoal, and produce the same results.

Note that an over-general rule is an incorrect rule, but not all incorrect rules are over-general.  


% ----------------------------------------------------------------------------
\subsection{Sources of Generality Issues}
\index{chunking!correctness}

\subsubsection{Over-specialization}

The main limitation of traditional chunking was that it would often produce rules that were very specific and could not be applied to many other situations. These \textit{over-specialized} rules lacked generality because they were not able to variablize anything except Soar identifiers and did not incorporate all of the knowledge described in the original rules, for example constraints on variable values.  This limitation was the main reason an alternate explanation-based approach was researched.  Specifically, EBC's identity-based variablization and constraint tracking/enforcement has eliminated the core source of this issue.

\subsubsection{Rule Repair}

There is one situation in which an agent may still learn an over-specialized rule.  It occurs when EBC repairs a rule that has unconnected conditions, which are conditions that have an identifier that is not linked to one of the states referenced in the rule.  Such rules are illegal and cannot be added to Soar's production memory. As described in Section \ref{CHUNKING-during-formation-validate}, EBC's repair process provides a connection by adding new conditions to the rule that provide a link from a state that is tested somewhere else in the rule to the unconnected condition or action. 

The only known situation in which repair can still occur is when an agent tests or augments a previous result.  A previous result is a working memory element that was originally created locally in the substate but then later became a result when a rule fired and connected it to the superstate.  If another substate rules later matches or augments such a previous result WME \emph{using a path relative to the local substate}, then EBC will have problems.  It will know that the WME is in the superstate -- so conditions that test the WME are considered operational and augmentations on that identifier are considered results -- but it won't know where in the superstate that working memory is located is and how it should be referenced in the learned rule. 

To repair the rule, EBC creates new grounding conditions to connect the unconnected identifier.  It performs a search through working memory to find the shortest path from a state to the identifier behind the unconnected element.   This adds specificity to the learned rule because these new conditions are based purely on what happened to be in working memory at that point.  So, adding them to the chunk constrains it to only match future situations where the previous result can be found on that same path. 

Since, nothing in the explanation dictated that particular path, the learned rules may be over-specialized. (But if an agent designer expects that the path should always exist, a repaired rule should match just as generally as a unrepaired rule.) Fortunately, new chunks can be learned to ameliorate this.  If a similar situation is encountered in the future but with a different path to the unconnected element, the chunk won't fire (the added grounding conditions won't match), which should cause the agent to subgoal and learn a similar chunk with a different set of grounding conditions.

To avoid this situation, an agent designer can isolate rules that form chunks by testing or augmenting the substructure of a previous result.  \emph{If those rules are modified so that they match the previous result WMEs through the superstate and not through the local state, EBC will be able create a valid rule without any repair.} 

To detect when this is happening, use the \soar{chunk stats} command. (See Section \ref{debugging-explanation-based-chunking} It will tell you if any of an agent's learned rules required repair.

\subsubsection{Over-generalization}
\index{chunking!correctness}
\index{chunk!overgeneral}

While over-specialization may no longer be a common problem, it is still possible to get over-general rules.  Several of the sources of correctness issues listed in the next section can produce over-general rules in certain situations.


% ----------------------------------------------------------------------------
\subsection{Sources of Correctness Issues}
\label{CHUNKING-correctness-issues}

\subsubsection{Missing Operator Selection Knowledge}

If an agent uses rules that create operator preferences to choose amongst multiple operators in the substate, it is possible that the reasoning behind those rules needs to be incorporated in any rule learned.  This topic is discussed in greater detail in Section \ref{CHUNKING-prior-osk}.  

EBC will incorporate relevant operator selection knowledge if you enable the chunk setting \soar{add-osk}, which is off by default. (See Section \ref{chunk-add-osk}.)

\subsubsection{Operators Selected Probabilistically}

If the problem-solving in a substate involves operators that were selected probabilistically, chunking will not be able to summarize the agent's reasoning into a correct rule.  For a rule to be correct, it must always produce the same result as a substate would have if the learned rule was not in production memory, which is impossible when operators are probabilistically selected.

Future versions of chunking will provide an option to prevent rules from forming when a probabilistically-selected operator was chosen during problem-solving.  Until then, agent engineers can disable learning in states that involve such reasoning.

\subsubsection{Collapsed Negative Reasoning}
\index{chunking!negated conditions}
\index{chunk!overgeneral}

\emph{Over-general chunks can be created when conditions in the explanation trace test for the absence of a working memory elements in the substate.} Since there is no clear way for chunking to generate a set of conditions that describe when a given working memory element would not exist in a substate, chunking can't represent that aspect of the problem-solving. 

Chunking can include negated tests if they test for the absence of superstate working memory elements.  So, the agent engineer can avoid using negated conditions for local data by either (1) designing the problem-solving so that the data that is being tested in the negation is already in the superstate or (2) make the data a result by attaching it to the superstate. This increases the number of chunks learned, but a negated condition of knowledge in the superstate can be incorporated correctly into learned rules.

Alternatively, turning off chunking's correctness filter \soar{allow-local-negations} will force Soar to reject chunks whose problem-solving involved a local negation. Note that there are many cases where local negations are perfectly safe to ignore, so Soar allows local negations by default.  In some agents, they are common enough that turning the filter on prevents most rules from being learned.

If you suspect that a rule may be over-general because of locally negated condition, you can verify whether such a condition was encountered during backtracing by using the \soar{chunk stats} command and \soar{explain stats} command.  See Sections \ref{debugging-explanation-based-chunking} and \ref{explain-stats} for more information.

\subsubsection{Not Testing Any Superstate Structures}
\label{CHUNKING-correctness-issues-exhaustion}
\index{chunk!overgeneral}

Over-general chunks can be created if a result of a subgoal is dependent on the creation of an impasse within the substate. For example, processing in a subgoal may consist of exhaustively applying all the operators in the problem space. If so, then a convenient way to recognize that all operators have applied and processing is complete is to wait for a state no-change impasse to occur. When the impasse occurs, a production can test for the resulting substate and create a result for the original subgoal. This form of state test builds over-general chunks because no pre-existing structure is relevant to the result that terminates the subgoal. The result is dependent only on the existence of the substate within a substate.

In these cases, EBC will learn a chunk with no conditions, which it will reject.  But the superstate result is still created by the substate rule that matched.  If a new rule is learned that uses that result, it will be over-general since the rule does not summarize the reasoning that led to the result, namely that all operators were exhaustively applied. 

\index{quiescence}
The current solution to this problem is a bit of a hack.  Soar allows an agent to signal to the architecture that a test for a substate is being made by testing for the \soar{\carat quiescence t} augmentation of the subgoal. If this special test is found in the explanation trace, EBC will not build a chunk. The history of this test is maintained, so that if the result of the substate is then used to produce further results for a superstate, no higher chunks will be built. 

\subsubsection{Disjunctive Context Conflation}

One source of incorrect rules occurs when multiple rules fire in a substate that test different structures in the superstate \emph{but create the same WME in the substate}. For example, there may be a rule that can match the superstate in several different ways, each time elaborating the local state with a WME indicating that at least one of these qualifying superstate WMEs existed. In such a situation, the rule would fire multiple times, but the result of the rule firings will be collapsed into creating a single WME in the substate. 

If this WME is then tested to create a result on the superstate, the chunk that is subsequently created can produce different behavior than the substate would have. In the original subgoal processing, all of the matches produced one substate WME.  That one substate WME created a single result in the superstate.  The chunk on the other hand will match each of the items that previously created the substate WME.  And the, each one of those chunk matches will create its own distinct result in the superstate.   Since this is different behavior than the original substate, this rule would be considered incorrect. 

If it were possible, EBC should learn a \textit{disjunctive conjunctive condition}, with each disjunction being the superstate conditions tested by each substate rule that had previously created the substate WME that was repeatedly asserted.  This is why this potential source of incorrect rules is called \textit{disjunctive context conflation}.

If this type of reasoning is needed, agents can move the conflating WME to the superstate.  The rule learned would then produce only one result regardless of the number of rules that repeatedly created that WME. 

\subsubsection{Generalizing knowledge retrieved from semantic or episodic memory}

Generalizing problem-solving based on knowledge recalled from an external memory system can be problematic for four main reasons.

\begin{enumerate}
	\item \textbf{Justification for a memory recall is opaque to agent} \hfill
	EBC does not have access to the reasoning behind why a piece of knowledge was recalled from a memory system.  For example, consider the case of a semantic memory that is recalled because it has the highest level of activation at a particular time.  In a future situation, the same semantic memory may not be the most active, in which case something else would be recalled and different problem-solving could occur.  Because of that possibility, the original rule is not guaranteed to produce the same result and hence could be incorrect.  (Note that this can also occur with episodic memory queries.)

	\item \textbf{Knowledge that changes after the learning episode} \hfill
	Semantic knowledge can be modified by the agent.  Different semantic knowledge can affect different problem-solving, in which case a rule based on the original problem-solving would be incorrect.  (Different recalled knowledge could affect which rules would match in the substate, or it could change which memory is now the best match to be recalled.)

	\item If the knowledge from semantic or episodic memory is retrieved directly within the substate, EBC will not directly incorporate that knowledge into the learned rule at all.
	
	\index{chunk!overgeneral}
	As described in Section \ref{CHUNKING-during-backtracing-operationality}, a chunk's conditions are based on the conditions in the explanation trace that tested knowledge linked to a superstate.  If semantic or episodic memory is recalled directly into the substate, then any conditions that test that recalled knowledge is not considered operational.  Since the learned rule may not be incorporating some of the reasoning and constraints that involved the recalled knowledge, the rule may be over-general.

	To avoid this situation, an agent can retrieve the knowledge in a higher-level state rather than the substate in which the rule is learned.

	\item %TODO
\end{enumerate}


% ----------------------------------------------------------------------------
% ----------------------------------------------------------------------------
\section{Usage}
\label{CHUNKING-usage}
\index{chunking-usage}

% ----------------------------------------------------------------------------
\subsection{Overview of the \soar{chunk} command}
\index{chunk (command)}

{\footnotesize
\begin{verbatim}
===================================================
           Chunk Commands and Settings
===================================================
? | help                                              Print this help listing
timers                                 [ on | OFF ]   Timing statistics (no args to print stats)
stats                                                 Print stats on learning that has occurred
------------------- Settings ----------------------
ALWAYS | never | only | except                        When Soar will learn new rules
bottom-only                            [ on | OFF ]   Learn only from bottom substate
naming-style                     [ numbered | RULE]   Simple names or rule-based name
max-chunks                                 50         Max chunks that can be learned (per phase)
max-dupes                                   3         Max duplicate chunks (per rule, per phase)
------------------- Debugging ---------------------
interrupt                              [ on | OFF ]   Stop Soar after learning from any rule
explain-interrupt                      [ on | OFF ]   Stop Soar after learning explained rule
warning-interrupt                      [ on | OFF ]   Stop Soar after detecting learning issue
------------------- Fine Tune ---------------------
singleton                                             Print all WME singletons
singleton                <type> <attribute> <type>    Add a WME singleton pattern
singleton -r             <type> <attribute> <type>    Remove a WME singleton pattern
----------------- EBC Mechanisms ------------------
add-ltm-links                          [ on | OFF ]   Recreate LTM links in original results
add-osk                                [ on | OFF ]   Incorporate operator selection knowledge
merge                                  [ ON | off ]   Merge redundant conditions
lhs-repair                             [ ON | off ]   Add grounding conds for unconnected LHS
rhs-repair                             [ ON | off ]   Add grounding conds for unconnected RHS
user-singletons                        [ ON | off ]   Use domain-specific singletons
---------- Correctness Guarantee Filters ----------   Allow rules to form that...
allow-local-negations                  [ ON | off ]   ...used local negative reasoning
allow-opaque*                          [ ON | off ]   ...used knowledge from a LTM recall
allow-missing-osk*                     [ ON | off ]   ...tested operators selected using OSK
allow-uncertain-operators*             [ ON | off ]   ...tested probabilistic operators
\end{verbatim}
* disabled
}

See Section \ref{chunk} for more detailed information about the \soar{chunk} command's settings.

% ----------------------------------------------------------------------------
\subsection{Enabling Procedural Learning}
\label{CHUNKING-usage-enable}

By default, explanation-based chunking is off.

\begin{itemize}
	\item To turn on chunking: \soar{chunk always}
	\item To turn off chunking: \soar{chunk never}
\end{itemize}

In real world agents, there may be certain problem spaces in which you don't want your agent to learn rules.  Chunking has a mechanism to allow agents to dynamically specify the states in which rules are learned. 

\begin{itemize}
	\item To turn off chunking in all states except ones manually flagged on: 
	\begin{itemize}
		\item Use \soar{chunk only} setting.
		\item Design an agent rule that executes the RHS action \soar{force-learn}, which only matches in states in which you want to learn rules.
	\end{itemize}
	\item To turn on chunking in all states except ones manually flagged off: 
	\begin{itemize}
		\item Use \soar{chunk except} setting.
		\item Design an agent rule that executes the RHS action \soar{dont-learn}, which only matches in states in which you don't want to learn rules.
\end{itemize}

Depending on your agent design, you may want to consider enabling the \soar{add-osk} option.  As of Soar 9.6.0, EBC does not incorporate operator selection knowledge into learned rules by default, since there is a performance cost and not all agents designs require its inclusion.  You may want to enable this option if your agent has rules that test knowledge in the superstate to create operator preferences in the substate.

See Section \ref{chunk} on page \pageref{chunk} for more information about the chunk command.


% ----------------------------------------------------------------------------
\subsection{Fine-tuning What Your Agent Learns}
\label{CHUNKING-usage-tuning}

\subsubsection{Prohibiting known sources of correctness issues}
\label{CHUNKING-usage-tuning-correctness}
\index{chunking!correctness}

It is theoretically possible to detect nearly all of the sources of correctness issues as they happen during execution.  Chunking includes options to prevent rules from forming when these situations are detected.  In Soar 9.6.0, only one filter is available, \soar{allow-local-negations}.  Future versions of Soar will include more correctness filters.

Note that it is still possible to detect that your agent may have encountered the known sources of correctness issues by looking at the output of the \soar{chunk stats} command.  It has specific statistics for some of the sources, while others can be gleaned indirectly.  For example, if the stats show that some rules required repair, you know that your agent was augmenting a previous result

\subsubsection{Using singletons to simplify a rule's conditions}
\label{CHUNKING-usage-tuning-conditions}

The state barrier opaqueness assumption can produce learned rules with seemingly duplicate conditions.  While these conditions are logically correct, they may be redundant because the nature of the domain may make it impossible for the two conditions to match different working memory elements.  For example, in the blocks-world domain, the fact that there can be only one gripper in the world means that having multiple conditions testing for a gripper would be redundant.  

\index{singleton}
\index{chunking!backtracing}
Soar allows agents to specify such known domain characteristics, which EBC will then use to create better rules that don't have such unnecessary conditions.  We call any working memory element that is guaranteed to only have a single possible value at any given time, a \textit{singleton}.  If EBC encounters two different conditions in the backtrace that both test the same superstate WME that matches a user singleton pattern, it will merge the two conditions. As described in Section \ref{CHUNKING-prior-identity}, there are several architectural singleton's that EBC already knows about.  To specify patters for domain-specific singletons, the \soar{chunk singleton} command can be used. 

See Section \ref{chunk} for more information about the chunk singleton command.

% ----------------------------------------------------------------------------
\subsection{Understanding What Was Learned}
% TODO

\subsubsection{Printing and Traces}
\index{chunking!backtracing}

To observe the backtracing process:

The watch command: \soar{trace backtracing -on} (See Section \ref{trace} on page \pageref{trace}). This prints out a trace of the conditions as they are collected.

\subsubsection{Chunking Statistics}

\subsubsection{Interrupting Execution To Examine Learning}

\subsubsection{Explaining Learning Episodes (The Explainer)}

\subsubsection{Visualizing Learning Episodes (The Visualizer)}


% ----------------------------------------------------------------------------
% ----------------------------------------------------------------------------
\section{Subtleties of EBC}
\label{CHUNKING-subtleties}

%TODO

% ----------------------------------------------------------------------------
\subsection{Chunks Based on Chunks}

% ----------------------------------------------------------------------------
\subsection{Chunks vs Justifications}
\index{justification}
\index{chunk}

Chunks are closely related to another type of rule called a \textit{justification}.  Justifications are also created when a substate creates a result for a superstate, the difference being that justifications are only built when learning is off.  These justifications are needed to decide whether the working memory elements in the result should get i-support or o-support in the superstate.  To do that, Soar needs to determine whether any rules involved in the creation of the result tested the selected operator in the superstate, which is exactly the same type of analysis that chunking does.

As a result, Soar uses a limited version of the chunking algorithm to do that.  It analyzes the substate problem-solving and learns a new, temporary rule, a ``justification'', which is added to production memory.  If this temporary rule tests an operator in the superstate, it gives the result o-support. (Note that when learning is on, a justification is not needed since the chunk will provide the correct support.)

Justifications use all the components described in the following sections and are even affected by the current chunk settings.\footnote{
	Even though they don't contain variables, justifications can be over-general because they don't incorporate enough knowledge, for example, operator selection knowledge.}
 You can even print justifications out like other rules.  The only differences between chunks and justifications are:
 
 \begin{enumerate}
	\item Every condition and action in a justification contain the literal values that matched.  Justifications contain no variables.\footnote{
		Justifications can have variables in the negated conditions and negated conjunctions of conditions of the justification.  They just don't have any variables in its positive conditions.}
	\item Justifications don't contain any of the value constraints that a chunk would have.
	\item Justifications get removed from production memory as soon as their conditions no longer match. 
 \end{enumerate}

 \subsubsection{Mixing Justifications and Chunks}
 
If an agent is using the \soar{only} or \soar{except} setting, then justifications will be built in states where learning is disabled and chunks will be built in states where learning is enabled.  In these situations, justifications also serve another purpose:  they provide an explanation of the results for future learning episodes in states that do have learning on.  EBC does this by retaining all of the extra information that chunks have but justifications do not, namely those extra tests and how things would have been variablized.  This allows EBC to learn chunks from justifications as readily as it can from hand-written rules and other chunks.

When mixing justifications and chunks, users may want to set EBC to record explanations of justifications as well as chunks.  This allows one to examine the reasoning behind a justification, which may be important if it later participates in the formation a chunk. See Section \ref{explain} for more information about the explainer's settings.

% ----------------------------------------------------------------------------
\subsection{Chunk Inhibition}
\index{chunking!inhibition}

If a newly learned chunk was immediately added to production memory, it would immediately match with the same working memory elements that participated in its creation.  This can be problematic if the production's actions include preferences for new working memory elements.  Consider the case where a substate proposes a new operator, which causes a chunk to be learned that also proposes a new operator. The chunk would immediately fire and create a preference for another new operator, which duplicates the operator preference that was the original result of the subgoal. 

To prevent this, \texbf{inhibition} is used. This means that each production that is built during chunking is considered to have already fired with the instantiation of the exact set of working memory elements used to create it. Note that this does not prevent a newly learned chunk from immediately matching other working memory elements that are present.

% ----------------------------------------------------------------------------
\subsection{Determining Which OSK Preferences are Relevant}
\label{CHUNKING-subtleties-osk}
\index{chunking!backtracing}

The following outline describes the logic that happens at each step. For a more detailed description of the various filters (but not the ROSK) see Section \ref{PREFERENCES} on page \pageref{PREFERENCES}. Note that depending on the set of preferences being processed, impasses may occur at some of these stages, in which case, no operator is selected and the ROSK is emptied. Moreover, if the candidate set is reduced to zero or one, the decision process will exit with a finalized ROSK. For simplicity's sake, this explanation assumes that there are no impasses and the decision process continues.

\begin{description}
	\item [Require Filter] 
	If an operator is selected based on a require preference, that preference is added to the ROSK. The logic behind this step is straightforward, the require preference directly resulted in the selection of the operator.
	\item [Prohibit/Reject Filters]
	If there exists at least one prohibit or reject preference, all prohibit and reject preferences for the eliminated candidates are added to the ROSK. The logic behind this stage is that the conditions that led to the exclusion of the prohibited and rejected candidates is what allowed the final operator to be selected from among that particular set of surviving candidates.
	\item [Better/Worse Filter]
	For every candidate that is not worse than some other candidate, add all better/worse preferences involving the candidate.
	\item [Best Filter]
	Add any best preferences for remaining candidates to the ROSK.
	\item [Worst Filter]
	If any remaining candidate has a worst preference which leads to that candidate being removed from consideration, that worst preference is added to the ROSK. Again, the logic is that the conditions that led to that candidate not being selected allowed the final operator to be chosen.
	\item [Indifferent Filter]
	This is the final stage, so the operator is now selected based on the agent's exploration policy. How indifferent preferences are added to the ROSK depends on whether any numeric indifferent preferences exist.
	\begin{enumerate}
		\item If there exists at least one numeric indifferent preference, then every numeric preference for the winning candidate is added to the ROSK. There can be multiple such preferences. Moreover, all binary indifferent preferences be- tween that winning candidate and candidates without a numeric preference are added.
		\item If all indifferent preferences are non-numeric, then any unary indifferent preferences for the winning candidate are added to the ROSK. Moreover, all binary indifferent preferences between that winning candidate and other candidates are added.
	\end{enumerate}
	The logic behind adding binary indifferent preferences between the selected operator and the other final candidates is that those binary indifferent preferences prevented a tie impasse and allowed the final candidate to be chosen by the exploration policy from among those mutually indifferent preferences.
\end{description}

Note that there may be cases where two or more rules create the same type of preference for a particular candidate. In those cases, only the first preference encountered is added to the ROSK. Adding all of them can produce over-specific chunks. It may still be possible to learn similar chunks with those other preferences if the agent subgoals again in a similar context.

Note also that operator selection knowledge is not tracked and incorporated into chunks by default. The setting must be turned on via the chunk command's \soar{add-osk} setting. See Section \ref{chunk} on page \pageref{chunk} for more information. 

The ROSK also affects the conditions of justifications, so the \soar{add-desirability-prefs} setting does have an effect on the agent even if learning is turned off.


% ----------------------------------------------------------------------------
\subsection{Generalizing Knowledge From Math and Other Right-Hand Side Functions}

Explanation-based chunking introduces the ability to learn rules whose actions perform right-hand side functions.  For example, the arithmetic demo agent learns the following rule:

%TODO

\index{chunking!RHS functions}
Unfortunately, this capability is limited to RHS functions.

This covers the incorrect chunks we can learn when we try to variablizing RHS functions.  The problem is that a condition that uses the output of a RHS function can have a constraint on its value that may limit the match.  We can't propagate the intermediate RHS function (or compose two functions), because there's no way to test the constraint in the same rule.  And just variablizing the RHS function arguments will lead to incorrect chunks.

Our solution:  Literalize identities in any intermediate opaque function .


% ----------------------------------------------------------------------------
\subsection{Situations in which a Chunk is Not Learned}

Soar learns a chunk every time a subgoal produces a result, unless one of the following conditions is true:

\begin{enumerate}
	\item \textbf{Chunking is off} \hfill
	This corresponds to the command \soar{chunk never}.  See Section \ref{chunk} on page \pageref{chunk} for details of \soar{chunk} and how to turn chunking on or off.

	\index{chunking!RHS functions}
	\index{RHS Function!dont-learn}
	\index{RHS Function!force-learn}
	\item \textbf{Chunking was only enabled for some states, and the subgoal in question is not one of them} \hfill
	When chunking is enabled via the \soar{only} or \soar{except} command, the agent must specify which states learning either occurs in or doesn't occur in, respectively.  For the \soar{except} setting, Soar will learn rules in all states in which a \soar{dont-learn} RHS production action was not executed.  Similarly, for the \soar{only} setting, Soar will learn rules in all states where a \soar{force-learn} RHS production action was executed.  See Section \ref{SYNTAX-pm-rhs-learning} on page \pageref{SYNTAX-pm-rhs-learning} for more information.

	This capability is provided for debugging and practical system development, but it is not part of the theory of Soar.

	\item \textbf{The chunk learned is a duplicate of another production or chunk already in production memory} \hfill

	In some rare cases, a duplicate production will not be detected because the order of the conditions or actions is not the same as an existing production.

	\index{chunking!correctness}
	\item \textbf{The problem-solving in the substate violated one of the enabled correctness guarantee filters}

	During the development of explanation-based chunking, we have developed a list of possible causes of incorrect chunks. EBC's correctness guarantee filters detect when those situations occur and prevents a chunk from being learned.  

	\index{chunk!overgeneral}
	For example, the \soar{allow-local-negations} filter will prevent a rule from being formed if the problem-solving that led to the result was dependent on a condition that tested whether a subgoal WME doesn't exist.  Since there is no practical way to determine why a piece of knowledge doesn't exist, testing a local negation can result in an over-general and incorrect chunk.  See Section \ref{CHUNKING-usage-tuning-correctness} on page \pageref{CHUNKING-usage-tuning-correctness} for more information. 

	Note that correctness filters have not yet been implemented for all the identified potential sources of correctness issues.

	\item \textbf{The chunking option \soar{bottom-only} is on and a chunk was already built in the bottom subgoal that generated the results}

	With \soar{bottom-only} chunking, chunks are learned only in states in which no subgoal has yet generated a chunk. In this mode, chunks are learned only for the ``bottom'' of the subgoal hierarchy and not the intermediate levels. With experience, the subgoals at the bottom will be replaced by the chunks, allowing higher level subgoals to be chunked .  See Section \ref{chunk} on page \pageref{chunk} for details of chunk used with the \soar{bottom-only} setting.

	\index{quiescence}
	\item \textbf{The problem-solving that led to the result contained a condition that tested the architecturally-created \soar{<state> \carat quiescence t} augmentation}

	This mechanism is motivated by the \textit{chunking from exhaustion} problem, where the results of a subgoal are dependent on the exhaustion of alternatives (see Section \ref{CHUNKING-correctness-issues-exhaustion} on page \pageref{CHUNKING-correctness-issues-exhaustion}). If this substate augmentation is encountered when determining the conditions of a chunk, then no chunk will be built for the currently considered action. This is recursive, so that if an un-chunked result is relevant to a second result, no chunk will be built for the second result. This does not prevent the creation of a chunk that would include \soar{\carat quiescence t} as a condition.

	\item \textbf{The problem-solving in the substate did not test any knowledge in the superstate}

	In these cases, the chunk learned does not have any conditions and is not a legal production.  \emph{Note that this creates an unusual persistence issue for any results that came out of the substate.}  Since a justification or chunk was not learned, there is no rule in the superstate that can provide either i-support or o-support for the result that came out of the substate.   Consequently, those result WMEs will be completely dependent on the rules that fired within the substate.  So, when the substate is removed, those results will also be removed.
